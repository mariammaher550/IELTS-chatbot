{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e163d0-d94c-402d-8efe-9938263eb557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.8/dist-packages (0.21.0.dev0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.8/dist-packages (0.4.0.dev0)\n",
      "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.8/dist-packages (0.39.1)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.36.0.dev0)\n",
      "Requirement already satisfied: trl in /usr/local/lib/python3.8/dist-packages (0.7.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.8/dist-packages (from peft) (0.3.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.8/dist-packages (from trl) (0.5.17)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (from trl) (2.13.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (10.2.10.91)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (11.4.0.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (4.8.0)\n",
      "Requirement already satisfied: triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\" in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (10.9.0.58)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.2.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.8/dist-packages (from tyro>=0.5.11->trl) (13.7.0)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.8/dist-packages (from tyro>=0.5.11->trl) (0.15)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from tyro>=0.5.11->trl) (1.6.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets->trl) (12.0.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets->trl) (0.70.14)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from datasets->trl) (0.3.6)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets->trl) (2.0.3)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets->trl) (3.8.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets->trl) (3.2.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate) (0.34.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate) (45.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.8/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate) (16.0.6)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.8/dist-packages (from triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch>=1.10.0->accelerate) (3.26.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.15.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->trl) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->trl) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->trl) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->trl) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->trl) (23.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->trl) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets->trl) (1.3.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.8/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate peft bitsandbytes transformers trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7d5e164-41e2-49dc-8d79-aee0f91431c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda115.so\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 115\n",
      "CUDA SETUP: Loading binary /usr/local/lib/python3.8/dist-packages/bitsandbytes/libbitsandbytes_cuda115.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/nvidia/lib'), PosixPath('/usr/local/nvidia/lib64')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/local/nvidia/lib:/usr/local/nvidia/lib64 did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/home/data/thesis/Untitled.ipynb')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('module'), PosixPath('//matplotlib_inline.backend_inline')}\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: Found duplicate ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] files: {PosixPath('/usr/local/cuda/lib64/libcudart.so'), PosixPath('/usr/local/cuda/lib64/libcudart.so.11.0')}.. We'll flip a coin and try one of these, in order to fail forward.\n",
      "Either way, this might cause trouble in the future:\n",
      "If you get `CUDA error: invalid device function` errors, the above might be the cause and the solution is to make sure only one ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] in the paths that we search based on your env.\n",
      "  warn(msg)\n",
      "/usr/local/lib/python3.8/dist-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aeff896a-eaf2-4b96-8581-00237f0bbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8cda715b-38c1-4cc3-a62d-7f219b5e36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name, bnb_config):\n",
    "    n_gpus = torch.cuda.device_count()\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        max_memory = {i: f'{40960}MB' for i in range(n_gpus)},\n",
    "    )\n",
    "\n",
    "    # Initializing the tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_eos_token = True)\n",
    "\n",
    "    # Needed for LLaMA tokenizer\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def create_bnb_config():\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    )\n",
    "\n",
    "    return bnb_config\n",
    "    \n",
    "def create_peft_config(modules):\n",
    "    \"\"\"\n",
    "    Create Parameter-Efficient Fine-Tuning config for your model\n",
    "    :param modules: Names of the modules to apply Lora to\n",
    "    \"\"\"\n",
    "    config = LoraConfig(\n",
    "        r=16,  # dimension of the updated matrices\n",
    "        lora_alpha=64,  # parameter for scaling\n",
    "        target_modules=modules,\n",
    "        lora_dropout=0.1,\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "\n",
    "    return config\n",
    "\n",
    "def preprocess_batch(batch, tokenizer, max_length):\n",
    "    \"\"\"\n",
    "    Tokenizing a batch\n",
    "    \"\"\"\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edba07e-623a-4f77-8d3c-4106b595cb62",
   "metadata": {},
   "source": [
    "# Loading Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4326f2b-6b14-4cc6-9ce5-ca05187ff224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model(\"elliotthwang/elliott_Llama-2-7b-hf\" , create_bnb_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2fce320-56bc-4ecd-8fbc-28af35a9c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, PeftModel\n",
    "\n",
    "\n",
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b916ce68-daa4-4dad-a291-482d3693f93d",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2aa74f1-cb94-467d-a889-a6d7e22c24c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-d5eaa2522004f691/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 5504.34it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 624.62it/s]\n",
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-d5eaa2522004f691/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n",
      "42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset(\"csv\", data_files=\"ielts_chat/datasets/ielts_buddy_dataset.csv\", split='train')\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76800bd1-3739-49b9-b0f5-c4484455cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_fn(sample):    \n",
    "    prompt = \"\"\"\n",
    "you are an IELTS examiner. your task is to evaluate a writing section in an IELTS academic\n",
    "exam. you have to provide overall band score in <BAND_SCORE> </BAND_SCORE> tags and detailed evaluation in <EVALUATION></EVALUATION> tags . I will provide you the grading\n",
    "criteria in <CRITERIA> </CRITERIA> tags. The user will send you the task and his answer and you should respond with a feedback on how well does the user follow the grading criteria and his score. Provide his score in this format <Score>Score</Score>.\n",
    "<CRITERIA>\n",
    "TASK RESPONSE (TR)\n",
    "For Task 2 of both AC and GT Writing tests, candidates are required to formulate and\n",
    "develop a position in relation to a given prompt in the form of a question or\n",
    "statement, using a minimum of 250 words. Ideas should be supported by evidence,\n",
    "and examples may be drawn from a candidate’s own experience.\n",
    "The TR criterion assesses:\n",
    "▪ how fully the candidate responds to the task.\n",
    "▪ how adequately the main ideas are extended and supported.\n",
    "▪ how relevant the candidate’s ideas are to the task.\n",
    "▪ how clearly the candidate opens the discourse, establishes their position and\n",
    "formulates conclusions.\n",
    "▪ how appropriate the format of the response is to the task.\n",
    "COHERENCE AND COHESION (CC)\n",
    "This criterion is concerned with the overall organisation and logical development of\n",
    "the message: how the response organises and links information, ideas and language.\n",
    "Coherence refers to the linking of ideas through logical sequencing, while cohesion\n",
    "refers to the varied and appropriate use of cohesive devices (e.g. logical connectors,\n",
    "conjunctions and pronouns) to assist in making clear the relationships between and\n",
    "within sentences.\n",
    "The CC criterion assesses:\n",
    "▪ the coherence of the response via the logical organisation of information\n",
    "and/or ideas, or the logical progression of the argument.\n",
    "▪ the appropriate use of paragraphing for topic organisation and presentation.\n",
    "▪ the logical sequencing of ideas and/or information within and across\n",
    "paragraphs.\n",
    "▪ the flexible use of reference and substitution (e.g. definite articles, pronouns).\n",
    "▪ the appropriate use of discourse markers to clearly mark the stages in a\n",
    "response, e.g. [First of all | In conclusion], and to signal the relationship between ideas and/or information, e.g. [as a result | similarly].\n",
    "\n",
    "LEXICAL RESOURCE (LR)\n",
    "This criterion refers to the range of vocabulary the candidate has used and the\n",
    "accuracy and appropriacy of that use in terms of the specific task.\n",
    "The LR criterion assesses:\n",
    "▪ the range of general words used (e.g. the use of synonyms to avoid repetition).\n",
    "▪ the adequacy and appropriacy of the vocabulary (e.g. topic-specific items,\n",
    "indicators of writer’s attitude).\n",
    "▪ the precision of word choice and expression.\n",
    "▪ the control and use of collocations, idiomatic expressions and sophisticated\n",
    "phrasing.\n",
    "▪ the density and communicative effect of errors in spelling.\n",
    "▪ the density and communicative effect of errors in word formation.\n",
    "GRAMMATICAL RANGE AND ACCURACY (GRA)\n",
    "This criterion refers to the range and accurate use of the candidate’s grammatical\n",
    "resource via the candidate’s writing at sentence level.\n",
    "The GRA criterion assesses:\n",
    "▪ the range and appropriacy of structures used in a given response (e.g. simple,\n",
    "compound and complex sentences).\n",
    "▪ the accuracy of simple, compound and complex sentences.\n",
    "▪ the density and communicative effect of grammatical errors.\n",
    "▪ the accurate and appropriate use of punctuation.\n",
    "</CRITERIA>\n",
    "\"\"\"\n",
    "    \n",
    "    prompt += f\"Here is the task:\\n <Task>{sample['Question']}</Task> \\n And here is my answer: \\n <Answer>{sample['Answer']}</Answer>\"\n",
    "            \n",
    "    sample['text'] = prompt\n",
    "    \n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72c56f5e-65f1-49aa-ad0c-34c036488b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are: ['Question', 'Answer', 'Feedback', 'Final Score', 'Unnamed: 4', 'text']\n",
      "\n",
      "you are an IELTS examiner. your task is to evaluate a writing section in an IELTS academic\n",
      "exam. you have to provide overall band score in <BAND_SCORE> </BAND_SCORE> tags and detailed evaluation in <EVALUATION></EVALUATION> tags . I will provide you the grading\n",
      "criteria in <CRITERIA> </CRITERIA> tags. The user will send you the task and his answer and you should respond with a feedback on how well does the user follow the grading criteria and his score. Provide his score in this format <Score>Score</Score>.\n",
      "<CRITERIA>\n",
      "TASK RESPONSE (TR)\n",
      "For Task 2 of both AC and GT Writing tests, candidates are required to formulate and\n",
      "develop a position in relation to a given prompt in the form of a question or\n",
      "statement, using a minimum of 250 words. Ideas should be supported by evidence,\n",
      "and examples may be drawn from a candidate’s own experience.\n",
      "The TR criterion assesses:\n",
      "▪ how fully the candidate responds to the task.\n",
      "▪ how adequately the main ideas are extended and supported.\n",
      "▪ how relevant the candidate’s ideas are to the task.\n",
      "▪ how clearly the candidate opens the discourse, establishes their position and\n",
      "formulates conclusions.\n",
      "▪ how appropriate the format of the response is to the task.\n",
      "COHERENCE AND COHESION (CC)\n",
      "This criterion is concerned with the overall organisation and logical development of\n",
      "the message: how the response organises and links information, ideas and language.\n",
      "Coherence refers to the linking of ideas through logical sequencing, while cohesion\n",
      "refers to the varied and appropriate use of cohesive devices (e.g. logical connectors,\n",
      "conjunctions and pronouns) to assist in making clear the relationships between and\n",
      "within sentences.\n",
      "The CC criterion assesses:\n",
      "▪ the coherence of the response via the logical organisation of information\n",
      "and/or ideas, or the logical progression of the argument.\n",
      "▪ the appropriate use of paragraphing for topic organisation and presentation.\n",
      "▪ the logical sequencing of ideas and/or information within and across\n",
      "paragraphs.\n",
      "▪ the flexible use of reference and substitution (e.g. definite articles, pronouns).\n",
      "▪ the appropriate use of discourse markers to clearly mark the stages in a\n",
      "response, e.g. [First of all | In conclusion], and to signal the relationship between ideas and/or information, e.g. [as a result | similarly].\n",
      "\n",
      "LEXICAL RESOURCE (LR)\n",
      "This criterion refers to the range of vocabulary the candidate has used and the\n",
      "accuracy and appropriacy of that use in terms of the specific task.\n",
      "The LR criterion assesses:\n",
      "▪ the range of general words used (e.g. the use of synonyms to avoid repetition).\n",
      "▪ the adequacy and appropriacy of the vocabulary (e.g. topic-specific items,\n",
      "indicators of writer’s attitude).\n",
      "▪ the precision of word choice and expression.\n",
      "▪ the control and use of collocations, idiomatic expressions and sophisticated\n",
      "phrasing.\n",
      "▪ the density and communicative effect of errors in spelling.\n",
      "▪ the density and communicative effect of errors in word formation.\n",
      "GRAMMATICAL RANGE AND ACCURACY (GRA)\n",
      "This criterion refers to the range and accurate use of the candidate’s grammatical\n",
      "resource via the candidate’s writing at sentence level.\n",
      "The GRA criterion assesses:\n",
      "▪ the range and appropriacy of structures used in a given response (e.g. simple,\n",
      "compound and complex sentences).\n",
      "▪ the accuracy of simple, compound and complex sentences.\n",
      "▪ the density and communicative effect of grammatical errors.\n",
      "▪ the accurate and appropriate use of punctuation.\n",
      "</CRITERIA>\n",
      "Here is the task:\n",
      " <Task>As countries have developed there has been a trend towards  smaller family sizes. Why does this happen?How does this affect society?</Task> \n",
      " And here is my answer: \n",
      " <Answer>Many countries around the world are becoming richer as they develop and at the same time these countries are seeing a reduction in the size of the family unit. This essay will discuss the reasons for this phenomenon and examine some of the possible effects it will have on society.\n",
      "\n",
      "One of the principal reasons for smaller family units is birth control. As a country develops and becomes richer, birth control becomes more readily available. This may be due to a rise in the number of medical clinics or the distribution of free contraception. The result of this is that people can choose family size. Another important factor is the rise in the levels of education that occur as a country develops, which means that women are more educated and more likely to be working. Consequently, many will want to delay having children and so will likely have fewer in the long-term. \n",
      "\n",
      "This can impact on society in a number of ways. One positive effect is that the population will fall, which will likely result in less poverty as there will be less competition for scarce resources. The parents can also provide a better education to their children as it will cost less, which will benefit society as a whole. A possible negative impact is that there will be fewer younger people in the workforce in the future, thus making the sustainability of future economic growth less certain.\n",
      "\n",
      "In conclusion, family size has fallen due to birth control and education, and this can have positive and negative impacts on society. Regardless of any impacts, this trend is likely to continue as countries around the world develop and become wealthier.\n",
      "\n",
      "</Answer>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# Add prompt to each sample\n",
    "print(\"Preprocessing dataset...\")\n",
    "dataset = dataset.map(prompt_fn)\n",
    "\n",
    "print(f'Column names are: {dataset.column_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30209616-83bf-41db-8e2a-6ec26df42051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are: ['input_ids', 'attention_mask']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "dataset = dataset.map(\n",
    "        partial(preprocess_batch, max_length=1024, tokenizer=tokenizer),\n",
    "        batched=True,\n",
    "        remove_columns=['Question', 'Answer', 'Feedback', 'Final Score', 'Unnamed: 4', 'text']\n",
    "    )\n",
    "\n",
    "print(f'Column names are: {dataset.column_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5deb2a01-b306-4437-81bd-3499f90c845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/csv/default-d5eaa2522004f691/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-71eef5039a117af9.arrow and /root/.cache/huggingface/datasets/csv/default-d5eaa2522004f691/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d/cache-5154a7ef6e59e88e.arrow\n"
     ]
    }
   ],
   "source": [
    "train_val = dataset.train_test_split(test_size=0.11, shuffle=True, seed=42)\n",
    "train_data = train_val[\"train\"]\n",
    "val_data = train_val[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d218563-1d70-4087-8341-d1d76df49d21",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6abdf91b-de56-45fc-974f-e04360e2fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using 8-bit optimizers with a version of `bitsandbytes` < 0.41.1. It is recommended to update your version as a major bug has been fixed in 8-bit optimizers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:46, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.735800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.332500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.177100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.132300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=20, training_loss=0.3444117307662964, metrics={'train_runtime': 49.2487, 'train_samples_per_second': 1.503, 'train_steps_per_second': 0.406, 'total_flos': 3019324142911488.0, 'train_loss': 0.3444117307662964, 'epoch': 2.0})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=5,\n",
    "    logging_steps=5,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to= None)\n",
    "\n",
    "  # Training parameters\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=training_args,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    tokenizer=tokenizer)\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026efc6-4a55-4b9e-931f-b9ad6d04fc8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
