{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be scraping data for IELTS essays with their corresponding feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Data of one Article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "BASE_URL = 'https://www.ieltsbuddy.com/essay-for-ielts.html'\n",
    "\n",
    "# Get the data from the url using BeautifulSoup\n",
    "response = requests.get(BASE_URL)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the methods used in advertising are unethical and unacceptable in todayâs society.  To what extent do you agree with this view?\n"
     ]
    }
   ],
   "source": [
    "question = \"\"\n",
    "question_parts = soup.find('div', {'class':'Stripe1 Stripe'}).find_all('b')\n",
    "\n",
    "for i in question_parts:\n",
    "    question += i.text\n",
    "\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The world that we live in today is dominated by advertising. Adverts are on television, on the World Wide Web, in the street and even on our mobile phones. However, many of the strategies used to sell a product or service can be considered immoral or unacceptable.\n",
      "\n",
      "To begin with, the fact that we cannot escape from advertising is a significant cause for complaint. Constant images and signs wherever we look can be very intrusive and irritating at times. Take for example advertising on the mobile phone. With the latest technology mobile companies are now able to send advertising messages via SMS to consumers' phones whenever they choose. Although we expect adverts in numerous situations, it now seems that there are very few places we can actually avoid them.\n",
      "\n",
      "A further aspect of advertising that I would consider unethical is the way that it encourages people to buy products they may not need or cannot afford. Children and young people in particular are influenced by adverts showing the latest toys, clothing or music and this can put enormous pressure on the parents to buy these products.\n",
      "\n",
      "In addition, the advertising of tobacco products and alcohol has long been a controversial issue, but cigarette adverts have only recently been banned in many countries. It is quite possible that alcohol adverts encourage excessive consumption and underage drinking, yet restrictions have not been placed on this type of advertising in the same way as smoking. \n",
      "\n",
      "It is certainly true to say that advertising is an everyday feature of our lives. Therefore, people are constantly being encouraged to buy products or services that might be too expensive, unnecessary or even unhealthy. In conclusion, many aspects of advertising do appear to be morally wrong and are not acceptable in today's society.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "essay = \"\"\n",
    "essay_parts = soup.find('div', {'class':'shadow'}).find_all('p')\n",
    "for i in range(len(essay_parts)-1):\n",
    "    data = essay_parts[i]\n",
    "    essay += data.text + \"\\n\\n\"\n",
    "    \n",
    "\n",
    "print(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This essay for IELTS is well organized as there are five clear paragraphs, each containing ideas that are relevant, well expressed, and related to the topic. \n",
      "\n",
      "Focusing on the language and structures in particular, the essay starts with an appropriate introductory sentence. Linking words are used accurately (However, In addition, Therefore).\n",
      "\n",
      "Phrases that signal opinions are evident (A further aspect of advertising that I would consider unethical. ..) backed up by reasons (...encourages people to buy products they may not need or cannot afford) and examples (Children and young people in particular, are influenced by adverts).\n",
      "\n",
      "In general, many other useful phrases are used, indicating a good control of language (It is quite possible... Many people consider. .. It is certainly true to say.. .).\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mosta\\AppData\\Local\\Temp\\ipykernel_6352\\652463405.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  comments_parts = soup.find('h3', text=\"Comments\").find_all_next('p')\n"
     ]
    }
   ],
   "source": [
    "# Getting all the p tags which are after the h3 tag which has text \"Comments\" and before the div which has class \"responsive_grid_block-2 responsive_grid_block-210346163\"\n",
    "comments_parts = soup.find('h3', text=\"Comments\").find_all_next('p')\n",
    "comments = \"\"\n",
    "for i in comments_parts:\n",
    "    if i.text == \"Next >>>\" or i.text == \"<<< Back\":\n",
    "        break\n",
    "\n",
    "    comments += i.text + \"\\n\\n\"\n",
    "\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data for all the links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URL = 'https://www.ieltsbuddy.com/ielts-sample-essays.html'\n",
    "\n",
    "# Get the data from the url using BeautifulSoup\n",
    "response = requests.get(BASE_URL)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = soup.find('div', {'class':'Liner'})\n",
    "\n",
    "links = content.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exracting data is done\n"
     ]
    }
   ],
   "source": [
    "# Create Data.json file and open it\n",
    "essays_list = []\n",
    "\n",
    "# Get a list of the files in the directory that there name starts with \n",
    "\n",
    "# for every link in links get the question, essay and comments\n",
    "for link in links:\n",
    "   \n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    except Exception as e:\n",
    "        continue\n",
    "    \n",
    "    if soup.find('div', {'class':'Stripe1 Stripe'}) is None:\n",
    "        continue\n",
    "\n",
    "    question = \"\"\n",
    "    question_parts = soup.find('div', {'class':'Stripe1 Stripe'}).find_all('b')\n",
    "\n",
    "    for i in question_parts:\n",
    "        question += i.text\n",
    "    \n",
    "    if soup.find('div', {'class':'shadow'}) is None:\n",
    "        continue\n",
    "\n",
    "    essay = \"\"\n",
    "    essay_parts = soup.find('div', {'class':'shadow'}).find_all('p')\n",
    "    for i in range(len(essay_parts)-1):\n",
    "        data = essay_parts[i]\n",
    "        essay += data.text + \"\\n\\n\"\n",
    "    \n",
    "    # Getting all the p tags which are after the h3 tag which has text \"Comments\" and before the div which has class \"responsive_grid_block-2 responsive_grid_block-210346163\"\n",
    "    if soup.find('h3', text=\"Comments\") is None:\n",
    "        continue\n",
    "    \n",
    "    comments_parts = soup.find('h3', text=\"Comments\").find_all_next('p')\n",
    "    comments = \"\"\n",
    "    for i in comments_parts:\n",
    "        if i.text == \"Next >>>\" or i.text == \"<<< Back\":\n",
    "            break\n",
    "\n",
    "        comments += i.text + \"\\n\\n\"\n",
    "\n",
    "    # Save the question, essay and comments in a json file\n",
    "    data = {\n",
    "        \"question\": question,\n",
    "        \"answer\": essay,\n",
    "        \"comments\": comments\n",
    "    }\n",
    "    \n",
    "    essays_list.append(data)\n",
    "\n",
    "print(\"Exracting data is done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Saving the scraped data in a json file\n",
    "file_path = 'data.json'\n",
    "\n",
    "with open(file_path, 'a') as json_file:\n",
    "    json.dump(essays_list, json_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
